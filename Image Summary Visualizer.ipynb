{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the imports from the sklearn module are statistical tools to help perform K-Means Clustering\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.cluster import KMeans\n",
    "# Imports the webbrowser module which will open a new tab\n",
    "import webbrowser\n",
    "# imports pandas and numpy, two important libraries for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# imports cv2, a computer vision library to help manipulate images\n",
    "import cv2\n",
    "# imports os, or operating system which will help perform system specific operations\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function that receives an image path and number of clusters k and returns a dictionary of clusters and values\n",
    "def image_summary(image_source, k):\n",
    "    \n",
    "    # Load image\n",
    "    image = cv2.imread(image_source)\n",
    "        \n",
    "    # Convert image to the HSV color space\n",
    "    image_hsv = cv2.cvtColor(image,cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # By default, images are stored as 3D objects with a width and height defined by the image resolution\n",
    "    # In addition, each pixel stores three pieces of information pertaining to color, in this case, H, S, and V\n",
    "    # Mathematrical operations on this 3D object is cumbersome and inefficient, so the flatten() method\n",
    "    # turns it into a 2D array for quicker operations.\n",
    "    # The first three values in the 2D array correspond with the 3 color values in the top-left pixel\n",
    "    # The next three values correspond with the 3 color values in next pixel to the right, etc.\n",
    "    # For example, the data structure of an image typically look like this:\n",
    "    # [[[1,2,3], [4,5,6]],\n",
    "    # [[7,8,9], [10,11,12]]\n",
    "    # The flatten argument transforms it to this:\n",
    "    # [1,2,3,4,5,6,7,8,9,10,11,12]\n",
    "    image_flat = image_hsv.flatten()\n",
    "\n",
    "    # Because of how the image is flatten, we know that the H, S, and V values reoccur at every third pixel\n",
    "    # at a slight different index i.e. All H values are at the 0th place, 3rd place, 6th place, 9th place and so on\n",
    "    # We take advantage of this to collect all the H, S, and V values into single variables\n",
    "    \n",
    "    # The h-channel. Takes every 3rd value from flatten image starting at 0th place\n",
    "    h = image_flat[0::3]\n",
    "    # The s-channel. Takes every 3rd value from flatten image starting at 1st place\n",
    "    s = image_flat[1::3]\n",
    "    # The v-channel. Takes every 3rd value from flatten image starting at 2nd place\n",
    "    v = image_flat[2::3]\n",
    "\n",
    "    # Create a dataframe from the pixel values\n",
    "    df = pd.DataFrame(data = h, columns = [\"h\"])\n",
    "    df['s'] = s\n",
    "    df['v'] = v\n",
    "\n",
    "    # H, S, and V values are at different scales. H values vary from 0-179 and S and V vary from 0-255\n",
    "    # Consequently, any clustering based on a geometric distance will be skewed\n",
    "    # To remedy this, the StandScaler() function brings everything onto a standard scale\n",
    "    \n",
    "    # initialize scaler\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Scaled features\n",
    "    scaler.fit(df)\n",
    "    df_scaled = scaler.transform(df)\n",
    "\n",
    "    # These two lines actually perform the K-Means clustering. Note that k is the same k passed in the initial argument\n",
    "    kmeans = KMeans(n_clusters = k)\n",
    "    kmeans.fit(df_scaled)\n",
    "\n",
    "    # Create a new column in the dataframe for the labels\n",
    "    # The labels themselves are simple numeric values that denote which pixels go into which cluster\n",
    "    # (ie, all pixels labeled as 1 are in the same cluster)\n",
    "    df[\"cluster\"] = kmeans.labels_\n",
    "\n",
    "    # create an empty dictionary to store summary values\n",
    "    colors = {}\n",
    "\n",
    "    # Iterate through the clusters, calculates the summary stats, and saves a masked image\n",
    "    for i in range(k):\n",
    "\n",
    "        # filter the dataframe by cluster\n",
    "        df_filter = df[df[\"cluster\"] == i]\n",
    "\n",
    "        # Calculates the summary stats. By default, the average is taken. If these need to change, this is the \n",
    "        # place to do it. Note that using the numpy library for calulations generally yield faster results\n",
    "        # The summary states are then stored in the dictionary.\n",
    "        colors[\"cluster \" + str(i)] = [\n",
    "            np.mean(df_filter[\"h\"]), \n",
    "            np.mean(df_filter[\"s\"]), \n",
    "            np.mean(df_filter[\"v\"])\n",
    "        ]\n",
    "\n",
    "        # create a \"mask\" based on the labels. This is basically the array that will dictate whether or not a pixel\n",
    "        # will be displayed in the image\n",
    "        detect = np.array([1 if x == i else 0 for x in kmeans.labels_], dtype='uint8')\n",
    "        \n",
    "        # reshape the mask into the dimensions of the picture\n",
    "        dims = image_hsv.shape\n",
    "        detect = detect.reshape(dims[0], dims[1])\n",
    "        \n",
    "        # Create a copy of the image\n",
    "        image_copy = image_hsv\n",
    "        \n",
    "        # create the masked image\n",
    "        output = cv2.bitwise_and(image_copy, image_copy, mask = detect)\n",
    "        \n",
    "        # Convert back to rgb for better visualization\n",
    "        output = cv2.cvtColor(output, cv2.COLOR_HSV2BGR)\n",
    "        \n",
    "        # save the image locally\n",
    "        cv2.imwrite(\"image_cluster_\" + str(i) + \".jpg\", output)\n",
    "\n",
    "    # Finally return the colors dictionary\n",
    "    return colors\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes a list of hsv values and converts it to the RGB colorspace.\n",
    "# This is purely a utility function that becomes useful later\n",
    "def hsv_to_rgb(hsv_vals):\n",
    "    \n",
    "    # round the the values\n",
    "    h = round(hsv_vals[0], 0)\n",
    "    s = round(hsv_vals[1], 0)\n",
    "    v = round(hsv_vals[2], 0)\n",
    "    \n",
    "    # To convert with openCV's rules, a simple one pixel \"image\" is created\n",
    "    image = [\n",
    "        [\n",
    "            [h, s, v]\n",
    "        ]\n",
    "    ]\n",
    "    \n",
    "    # convert to BGR colorspace\n",
    "    image = cv2.cvtColor(np.uint8(image), cv2.COLOR_HSV2BGR)\n",
    "    \n",
    "    # Get the pixel values in an array\n",
    "    pixel = image[0][0]\n",
    "    \n",
    "    # Because openCV stores it as a BGR, the reverse is stored in a list and returned for the traditional RGB format\n",
    "    return [pixel[2], pixel[1], pixel[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes a path and number of clusters k and creates an html file with the summary statistics and sample color \n",
    "# Note that a html file is the basic bare-bones component to a static website. This provides a useful frame work\n",
    "# for displaying data and information in an organized way. If running this on Jupyter Notebooks, the web browswer\n",
    "# will be open anyway and will open a new tab to render the html file\n",
    "def get_summary_visual(path, k):\n",
    "    \n",
    "    # Get the photo data\n",
    "    summary = image_summary(path, k)\n",
    "    \n",
    "    # write the start of the html file\n",
    "    start = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "\n",
    "<html>\n",
    "\n",
    "    <body>\n",
    "        <h>Image Summary</h>\n",
    "        <br>\n",
    "    \"\"\"\n",
    "    \n",
    "    # start the body of the html as a blank\n",
    "    body = \"\"\n",
    "    \n",
    "    # For each entry in the summary (ie, that colors dictionary from the image_summary() function), \n",
    "    # add the details to the html file\n",
    "    for key in summary:    \n",
    "        \n",
    "        # The hsv values stored in a nice variable\n",
    "        hsv_cluster = summary[key]\n",
    "        \n",
    "        # Convert the hsv values into RGB values\n",
    "        rgb_cluster = hsv_to_rgb(hsv_cluster)\n",
    "        \n",
    "        # Concat the body of the html and use f-strings to \"fill in blanks\" for key summary statistics\n",
    "        body = body + f\"\"\"      \n",
    "        <p>{key}</P>\n",
    "        <p>Average H: {hsv_cluster[0]}</p>\n",
    "        <p>Average S: {hsv_cluster[1]}</P>\n",
    "        <p>Average V: {hsv_cluster[2]}</p>\n",
    "        <div style =\"background-color:rgb({rgb_cluster[0]},{rgb_cluster[1]},{rgb_cluster[2]});height: 50px;width: 50px;\" ></div>\n",
    "        <img src = \"image_cluster_{key[8:]}.jpg\">\n",
    "        <br>\n",
    "        \"\"\"\n",
    "    \n",
    "    # Write a closing\n",
    "    end = \"\"\"\n",
    "    </body>\n",
    "</html>\n",
    "    \"\"\"\n",
    "    \n",
    "    # Right now, all the components to the HTML file are in separate varaibles\n",
    "    # Concat all the elements together into a single, cohesive html document\n",
    "    html = start + body + end\n",
    "    \n",
    "    # write the html locally\n",
    "    with open(\"image_summary.html\", 'w') as file:\n",
    "        file.write(html)\n",
    "    \n",
    "    # Get the working directory, so the user doesn't have to manually configure the path to the file\n",
    "    cwd = os.getcwd()\n",
    "    \n",
    "    # Geth the absolute path\n",
    "    path = cwd + \"\\\\\" + \"image_summary.html\"\n",
    "    \n",
    "    # open the html file in the webbrowser\n",
    "    webbrowser.open(path, new=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.629608631134033\n"
     ]
    }
   ],
   "source": [
    "# This is the point where user input is required!!\n",
    "\n",
    "# All the code above supports this single line\n",
    "# The first argument is the path to the file of interest\n",
    "# Note that \"\\\" is a break character that interferes with how strings of text are read\n",
    "# Consequently, add the letter \"r\" in front of the destination name to avoid issues with parsing text\n",
    "# The second argument is K, used for K-Means clustering\n",
    "# Depending on the size of the image and the value k, this may take several minutes to complete\n",
    "# Generally, larger images and larger values of K take longer to complete\n",
    "get_summary_visual(r\"C:\\Users\\Example\\FlowerClassification\\Observations\\123.jpg\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
